{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_heart=pd.read_csv('Heart_Modul2.csv')\n",
    "df_heart.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart2=df_heart.drop('Name',axis=1)\n",
    "df_heart2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart2['ChestPainType' ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data null \\n\",df_heart2.isnull().sum())\n",
    "print(\"\\ndata kosong \\n\",df_heart2.empty)\n",
    "print(\"\\ndata nan \\n\",df_heart2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_chole = df_heart2['Cholesterol'].median()\n",
    "\n",
    "print(median_chole)\n",
    "\n",
    "df_heart2['Cholesterol' ] = df_heart2['Cholesterol' ].fillna(median_chole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_heart2['Cholesterol' ].value_counts())\n",
    "\n",
    "print(\"data null \\n\",df_heart2.isnull().sum())\n",
    "print(\"\\ndata kosong \\n\",df_heart2.empty)\n",
    "print(\"\\ndata nan \\n\",df_heart2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sebelum drop missing value\",df_heart2.shape)\n",
    "df_heart2 = df_heart2.dropna(how=\"any\",inplace=False)\n",
    "print(\"Sesudah drop missing value\" ,df_heart2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart2['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sebelum drop data dengan gender Bi \",df_heart2.shape)\n",
    "df_heart2=df_heart2[df_heart2['Sex'] != 'Bi' ]\n",
    "print(\"Sesudah drop data dengan gender Bi \", df_heart2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sebelum Pengecekan data duplikat, \", df_heart2.shape)\n",
    "df_heart3=df_heart2.drop_duplicates(keep='last')\n",
    "print(\"Setelah Pengecekan data duplikat, \", df_heart3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df_heart3.drop(columns=['HeartDisease'],axis=1)\n",
    "y=df_heart3['HeartDisease' ]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=79)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. preprocessing import OneHotEncoder\n",
    "from sklearn. compose import make_column_transformer\n",
    "\n",
    "kolom_kategori=['Sex','ChestPainType', 'RestingECG','ExerciseAngina','ST_Slope']\n",
    "\n",
    "transform = make_column_transformer(\n",
    "(OneHotEncoder(), kolom_kategori), remainder='passthrough'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_enc=transform.fit_transform(x_train)\n",
    "x_test_enc=transform. fit_transform(x_test)\n",
    "\n",
    "df_train_enc=pd.DataFrame(x_train_enc,columns=transform.get_feature_names_out())\n",
    "df_test_enc=pd. DataFrame(x_test_enc, columns=transform.get_feature_names_out())\n",
    "\n",
    "df_train_enc.head(10)\n",
    "df_test_enc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectPercentile ,SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "pipe_svm = Pipeline(steps=[\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('feat_select', SelectKBest()),\n",
    "    ('clf', SVC(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "params_grid_svm = [\n",
    "    {\n",
    "        'scale': [MinMaxScaler()],\n",
    "        'feat_select__k':np.arange(2,6),\n",
    "        'clf__kernel': ['poly','rbf'],\n",
    "        'clf__C':[0.1,1],\n",
    "        'clf__gamma':[0.1, 1]\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'scale': [MinMaxScaler()],\n",
    "        'feat_select':[SelectPercentile()],\n",
    "        'feat_select__percentile':np.arange(20,50),\n",
    "        'clf__kernel': ['poly', 'rbf'],\n",
    "        'clf__C':[ 0.1, 1],\n",
    "        'clf__gamma': [0.1, 1]\n",
    "    },\n",
    "    {\n",
    "        'scale': [StandardScaler()],\n",
    "        'feat_select__k':np.arange(2,6),\n",
    "        'clf__kernel': ['poly','rbf'],\n",
    "        'clf__C':[0.1, 1],\n",
    "        'clf__gamma':[0.1, 1]\n",
    "    },\n",
    "    {\n",
    "        'scale': [StandardScaler()],\n",
    "        'feat_select': [SelectPercentile()],\n",
    "        'feat_select__percentile':np.arange(20,50),\n",
    "        'clf__kernel': ['poly', 'rbf'],\n",
    "        'clf__C':[0.1, 1],\n",
    "        'clf__gamma': [0.1, 1]\n",
    "    }\n",
    "]\n",
    "\n",
    "estimator_svm = Pipeline(pipe_svm)\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=79)\n",
    "\n",
    "GSCV_SVM = GridSearchCV(pipe_svm, params_grid_svm, cv=SKF)\n",
    "\n",
    "GSCV_SVM.fit(x_train_enc, y_train)\n",
    "print(\"GSCV training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV Score : {}\".format(GSCV_SVM.best_score_))\n",
    "\n",
    "print(\"Test Score: {}\".format(GSCV_SVM.best_estimator_.score(x_test_enc, y_test)))\n",
    "\n",
    "print(\"Best model:\", GSCV_SVM.best_estimator_)\n",
    "mask = GSCV_SVM.best_estimator_.named_steps['feat_select' ].get_support()\n",
    "print(\"Best features:\", df_train_enc.columns[mask])\n",
    "\n",
    "\n",
    "SVM_pred = GSCV_SVM.predict(x_test_enc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, SVM_pred, labels=GSCV_SVM. classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=GSCV_SVM.classes_)\n",
    "disp.plot()\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report SVM:\\n\", classification_report(y_test, SVM_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "pipe_RF=[('data scaling', StandardScaler()),\n",
    "         ('feature select', SelectKBest()),\n",
    "         ('clf', RandomForestClassifier(random_state=79,class_weight='balanced'))]\n",
    "\n",
    "params_grid_RF = [{\n",
    "    'data scaling': [StandardScaler()],\n",
    "    'feature select__k': np.arange(2, 6),\n",
    "    'clf__max_depth': np.arange(4, 5),\n",
    "    'clf__n_estimators': [100, 150]\n",
    "},\n",
    "{\n",
    "    'data scaling': [StandardScaler()],\n",
    "    'feature select': [SelectPercentile()],\n",
    "    'feature select__percentile': np.arange(20, 50),\n",
    "    'clf__max_depth': np.arange(4, 5),\n",
    "    'clf__n_estimators': [100, 150]\n",
    "},\n",
    "{\n",
    "    'data scaling': [MinMaxScaler()],\n",
    "    'feature select__k': np.arange(2, 6),\n",
    "    'clf__max_depth': np.arange(4,5),\n",
    "    'clf__n_estimators': [100, 150]\n",
    "},\n",
    "{\n",
    "    'data scaling': [MinMaxScaler()],\n",
    "    'feature select': [SelectPercentile()],\n",
    "    'feature select__percentile': np.arange(20, 50),\n",
    "    'clf__max_depth': np.arange(4, 5),\n",
    "    'clf__n_estimators': [100, 150]\n",
    "}\n",
    "]\n",
    "\n",
    "estimator_RF = Pipeline(pipe_RF)\n",
    "GSCV_RF=GridSearchCV(estimator_RF,params_grid_RF,cv=SKF)\n",
    "GSCV_RF.fit(x_train_enc,y_train)\n",
    "\n",
    "print(\"GSCV training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV Score: {}\".format(GSCV_RF.best_score_))\n",
    "print(\"Test Score: {}\".format(GSCV_RF.best_estimator_.score(x_test_enc, y_test)))\n",
    "print(\"Best model:\", GSCV_RF.best_estimator_)\n",
    "\n",
    "mask = GSCV_RF.best_estimator_.named_steps['feature select' ].get_support()\n",
    "print(\"Best features:\", df_train_enc.columns[mask])\n",
    "\n",
    "\n",
    "RF_pred = GSCV_RF.predict(x_test_enc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, RF_pred, labels=GSCV_RF.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=GSCV_RF.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification report RF: \\n\", classification_report(y_test, RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_GBT = Pipeline(steps=[\n",
    "        ('feat_select',SelectKBest()),\n",
    "        ('clf', GradientBoostingClassifier(random_state=79))])\n",
    "\n",
    "params_grid_GBT=[\n",
    "    {\n",
    "        'feat_select__k': np.arange(2,6),\n",
    "        'clf__max_depth': [*np.arange(4,5)],\n",
    "        'clf__n_estimators':[100,150],\n",
    "        'clf__learning_rate': [0.01,0.1,1]\n",
    "    },\n",
    "    {\n",
    "        'feat_select':[SelectPercentile()],\n",
    "        'feat_select__percentile':np.arange(20,50),\n",
    "        'clf__max_depth': [*np.arange(4,5)],\n",
    "        'clf__n_estimators': [100,150],\n",
    "        'clf__learning_rate' : [0.01,0.1,1]\n",
    "    },\n",
    "    {\n",
    "        'feat_select__k': np.arange(2,6),\n",
    "        'clf__max_depth': [*np.arange(4,5)],\n",
    "        'clf__n_estimators': [100,150],\n",
    "        'clf__learning_rate': [0.01,0.1,1]\n",
    "    },\n",
    "    {\n",
    "        'feat_select':[SelectPercentile()],\n",
    "        'feat_select__percentile':np.arange(20,50),\n",
    "        'clf__max_depth': [*np.arange(4,5)],\n",
    "        'clf__n_estimators': [100,150],\n",
    "        'clf__learning_rate':[0.01,0.1,1]\n",
    "    }\n",
    "]\n",
    "\n",
    "GSCV_GBT = GridSearchCV(pipe_GBT,params_grid_GBT,cv=StratifiedKFold(n_splits=5))\n",
    "GSCV_GBT.fit(x_train_enc,y_train)\n",
    "print(\"GSCV Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV Score : {}\".format(GSCV_GBT.best_score_))\n",
    "print(\"Test Score : {}\".format(GSCV_GBT.best_estimator_.score(x_test_enc, y_test)))\n",
    "print(\"Best model: \", GSCV_GBT.best_estimator_)\n",
    "\n",
    "mask = GSCV_GBT.best_estimator_.named_steps['feat_select'].get_support()\n",
    "print(\"Best features: \", df_train_enc.columns[mask])\n",
    "\n",
    "RF_pred = GSCV_GBT.predict(x_test_enc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, RF_pred, labels=GSCV_GBT.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=GSCV_GBT.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.title(\"GBT Confusion Matrix\")\n",
    "plt.show\n",
    "\n",
    "print(\"Classification report GBT: \\n\", classification_report(y_test, RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('GBT_heartDisease_model.pkl','wb') as r:\n",
    "    pickle.dump((GSCV_RF),r)\n",
    "\n",
    "    print(\"Model GBT berhasil disimpan\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
